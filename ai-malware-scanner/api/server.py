import os
import json
import tempfile
import hashlib
import threading
from flask import Flask, request, jsonify
from flask_cors import CORS
import sys
import logging
import time
import re
import math
from pathlib import Path
import requests
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

# Add parent directory to path to allow importing from other modules
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import proper static analysis modules
try:
    import pefile
    HAS_PEFILE = True
except ImportError:
    HAS_PEFILE = False
    logging.warning("pefile not installed - PE-specific analysis will be limited")

from static_analysis.entropy import shannon_entropy
from static_analysis.analyze import extract_static_features, vectorize_features
from utils.threat_intel import query_threat_intel

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*", "supports_credentials": True}})

# Potentially suspicious file extensions
SUSPICIOUS_EXTENSIONS = {
    '.exe', '.dll', '.com', '.bat', '.cmd', '.ps1', '.vbs', '.js', '.jar', '.hta', '.scr', '.pif',
    '.msi', '.vbe', '.jse', '.wsf', '.wsh', '.reg', '.vb', '.vba', '.lnk', '.py', '.rb'
}

# Scan status storage
scan_status = {
    "status": "idle",
    "stats": {
        "total_files": 0,
        "scanned_files": 0,
        "malicious_files": 0,
        "error_files": 0
    },
    "suspicious_files": []
}

# Real-time monitoring observers
observers = []

@app.route('/ping', methods=['GET'])
def ping():
    logger.info("Ping request received")
    return jsonify({"status": "ok", "message": "API server is running"})

@app.route('/upload', methods=['POST'])
def upload_file():
    try:
        if 'file' not in request.files:
            return jsonify({"error": "No file part in the request"}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({"error": "No file selected"}), 400
        
        temp_dir = tempfile.gettempdir()
        file_path = os.path.join(temp_dir, file.filename)
        file.save(file_path)
        
        logger.info(f"File uploaded: {file.filename}")
        
        features = extract_static_features(file_path)
        if not features:
            return jsonify({"error": "Could not extract features from file"}), 400
        
        risk_score, risk_level, suspicious_indicators = calculate_risk_score(features, file_path)
        
        # Get threat intelligence
        file_hash = calculate_file_hash(file_path)
        threat_intel = query_threat_intel(file_hash)
        
        result = {
            "filename": file.filename,
            "combined_risk_score": risk_score,
            "static_analysis": {
                "prediction": {
                    "label": "malicious" if risk_score > 0.7 else "suspicious" if risk_score > 0.4 else "benign",
                    "confidence": risk_score
                },
                "features": features
            },
            "dynamic_analysis": {
                "risk_level": risk_level,
                "suspicious_indicators": suspicious_indicators,
                "network_connections": [],
                "file_activity": []
            },
            "threat_intelligence": threat_intel
        }
        
        try:
            os.remove(file_path)
        except Exception as e:
            logger.warning(f"Could not remove temporary file: {e}")
        
        return jsonify(result)
    
    except Exception as e:
        logger.error(f"Error processing upload: {str(e)}")
        return jsonify({"error": f"Server error: {str(e)}"}), 500

@app.route('/threat-intel', methods=['POST'])
def threat_intelligence():
    try:
        data = request.json
        if not data or 'file_hash' not in data:
            return jsonify({"error": "No file hash provided"}), 400
        
        file_hash = data['file_hash']
        result = query_threat_intel(file_hash)
        return jsonify(result)
    
    except Exception as e:
        logger.error(f"Error in threat intelligence query: {str(e)}")
        return jsonify({"error": f"Server error: {str(e)}"}), 500

class RealTimeHandler(FileSystemEventHandler):
    def on_created(self, event):
        if not event.is_directory:
            file_path = event.src_path
            if is_file_suspicious(file_path):
                logger.warning(f"New suspicious file detected: {file_path}")
                features = extract_static_features(file_path) or basic_file_analysis(file_path)
                risk_score, _, _ = calculate_risk_score(features, file_path)
                scan_status["suspicious_files"].append({
                    "path": file_path,
                    "size": features.get("file_size", 0),
                    "risk_score": risk_score,
                    "timestamp": time.time()
                })

def start_realtime_monitoring(path):
    event_handler = RealTimeHandler()
    observer = Observer()
    observer.schedule(event_handler, path, recursive=True)
    observer.start()
    logger.info(f"Started real-time monitoring on {path}")
    return observer

@app.route('/scan/system', methods=['POST'])
def scan_system():
    global scan_status, observers
    try:
        # Stop existing observers
        for observer in observers:
            observer.stop()
        observers = []
        
        scan_status = {
            "status": "running",
            "stats": {
                "total_files": 0,
                "scanned_files": 0,
                "malicious_files": 0,
                "error_files": 0
            },
            "suspicious_files": []
        }
        
        scan_thread = threading.Thread(target=scan_system_task)
        scan_thread.daemon = True
        scan_thread.start()
        
        return jsonify({"message": "System scan started", "status": "running"})
    
    except Exception as e:
        logger.error(f"Error starting system scan: {str(e)}")
        return jsonify({"error": f"Server error: {str(e)}"}), 500

def scan_directory(path, recursive=False):
    try:
        # For Windows drives, ensure the path format is correct by using raw strings
        # and normalizing drive letters
        if os.name == 'nt' and path and len(path) >= 2 and path[1] == ':':
            # Normalize drive letter to uppercase and ensure path uses standard format
            drive_letter = path[0].upper()
            path = drive_letter + path[1:]
            
            # Log detailed path information for debugging
            logger.info(f"Windows drive path detected: {path}")
            
            # Use raw string to avoid escape character issues
            if not os.path.exists(fr"{path}"):
                # Try alternative path resolution
                alt_path = os.path.abspath(path)
                logger.warning(f"Direct path check failed. Trying absolute path: {alt_path}")
                
                if not os.path.exists(alt_path):
                    logger.error(f"Path does not exist (both methods failed): {path}")
                    return {
                        "total_files": 0,
                        "malicious_files": 0, 
                        "error_files": 1,
                        "suspicious_files": []
                    }
                else:
                    path = alt_path
        else:
            # Standard path normalization for non-Windows drive paths
            normalized_path = os.path.normpath(path)
            logger.info(f"Scanning path: {normalized_path}")
            
            if not os.path.exists(normalized_path):
                logger.error(f"Path does not exist: {normalized_path}")
                return {
                    "total_files": 0,
                    "malicious_files": 0, 
                    "error_files": 1,
                    "suspicious_files": []
                }
            path = normalized_path
            
        # For single file scanning
        if os.path.isfile(path):
            logger.info(f"Processing single file: {path}")
            try:
                total_files = 1
                features = extract_static_features(path) or basic_file_analysis(path)
                risk_score, risk_level, indicators = calculate_risk_score(features, path)
                malicious_files = 1 if risk_score > 0.4 else 0
                suspicious_files = []
                if risk_score > 0.4:
                    suspicious_files.append({
                        "path": path,
                        "size": features.get("file_size", 0),
                        "type": os.path.splitext(path)[1].lower(),
                        "risk_score": risk_score,
                        "risk_level": risk_level,
                        "indicators": indicators[:3]
                    })
                return {
                    "total_files": total_files,
                    "malicious_files": malicious_files,
                    "error_files": 0,
                    "suspicious_files": suspicious_files
                }
            except Exception as e:
                logger.error(f"Error scanning file {path}: {str(e)}")
                return {
                    "total_files": 1,
                    "malicious_files": 0,
                    "error_files": 1,
                    "suspicious_files": []
                }
        
        # Modified directory scanning to only focus on executable files
        logger.info(f"Scanning directory for executable files: {path}")
        total_files = 0
        malicious_files = 0
        error_files = 0
        suspicious_files = []
        
        # Build a list of all executable file paths first
        executable_files = []
        for root, dirs, files in os.walk(str(path)):
            for file in files:
                file_ext = os.path.splitext(file)[1].lower()
                if file_ext in SUSPICIOUS_EXTENSIONS:
                    file_path = os.path.join(root, file)
                    if os.path.exists(file_path) and os.access(file_path, os.R_OK):
                        try:
                            if os.path.getsize(file_path) <= 100 * 1024 * 1024:  # Skip files larger than 100MB
                                executable_files.append(file_path)
                                total_files += 1
                        except Exception:
                            # Skip files with access issues
                            pass
            
            if not recursive:
                break
        
        logger.info(f"Found {len(executable_files)} potential executable files to scan")
        
        # Now scan only the executable files
        for file_path in executable_files:
            try:
                features = extract_static_features(file_path) or basic_file_analysis(file_path)
                if features:  # Only process if we got features back
                    risk_score, risk_level, indicators = calculate_risk_score(features, file_path)
                    if risk_score > 0.4:
                        malicious_files += 1
                        suspicious_files.append({
                            "path": file_path,
                            "size": features.get("file_size", 0),
                            "type": os.path.splitext(file_path)[1].lower(),
                            "risk_score": risk_score,
                            "risk_level": risk_level,
                            "indicators": indicators[:3]
                        })
            except Exception as e:
                logger.error(f"Error scanning file {file_path}: {str(e)}")
                error_files += 1
                
        return {
            "total_files": total_files,
            "malicious_files": malicious_files,
            "error_files": error_files,
            "suspicious_files": suspicious_files
        }
    
    except Exception as e:
        logger.error(f"Error in scan_directory function: {str(e)}")
        return {
            "total_files": 0,
            "malicious_files": 0, 
            "error_files": 1,
            "suspicious_files": []
        }

def scan_system_task():
    global scan_status, observers
    try:
        system_paths = [
            os.environ.get('SystemDrive', 'C:') + '\\',
            os.environ.get('USERPROFILE'),
            tempfile.gettempdir()
        ]
        
        # Start real-time monitoring
        observers = [start_realtime_monitoring(path) for path in system_paths if path]
        
        scan_status["status"] = "running"
        scan_status["stats"]["total_files"] = 0
        scan_status["stats"]["scanned_files"] = 0
        scan_status["stats"]["malicious_files"] = 0
        scan_status["stats"]["error_files"] = 0
        scan_status["suspicious_files"] = []
        
        for path in system_paths:
            if path:
                logger.info(f"Scanning system path: {path}")
                results = scan_directory(path, recursive=True)
                
                scan_status["stats"]["total_files"] += results["total_files"]
                scan_status["stats"]["scanned_files"] += results["total_files"]
                scan_status["stats"]["malicious_files"] += results["malicious_files"]
                scan_status["stats"]["error_files"] += results["error_files"]
                scan_status["suspicious_files"].extend(results["suspicious_files"])
                
        scan_status["status"] = "completed"
        
    except Exception as e:
        logger.error(f"Error in system scan task: {str(e)}")
        scan_status["status"] = "error"
    finally:
        pass  # Observers continue running for real-time monitoring

@app.route('/scan/drive', methods=['POST'])
def scan_drive():
    global scan_status
    try:
        data = request.json
        if not data or 'path' not in data:
            return jsonify({"error": "No path provided"}), 400

        path = data['path']
        recursive = data.get('recursive', False)
        
        scan_status = {
            "status": "running",
            "stats": {
                "total_files": 0,
                "scanned_files": 0,
                "malicious_files": 0,
                "error_files": 0
            },
            "suspicious_files": []
        }
        
        def scan_task():
            nonlocal path, recursive
            try:
                results = scan_directory(path, recursive)
                
                scan_status["stats"]["total_files"] = results["total_files"]
                scan_status["stats"]["scanned_files"] = results["total_files"]
                scan_status["stats"]["malicious_files"] = results["malicious_files"]
                scan_status["stats"]["error_files"] = results["error_files"]
                scan_status["suspicious_files"] = results["suspicious_files"]
                scan_status["status"] = "completed"
                
            except Exception as e:
                logger.error(f"Error in scan task: {str(e)}")
                scan_status["status"] = "error"
        
        scan_thread = threading.Thread(target=scan_task)
        scan_thread.daemon = True
        scan_thread.start()
        
        return jsonify({
            "message": f"Scan started for {path} (recursive={recursive})", 
            "status": "running"
        })
    
    except Exception as e:
        logger.error(f"Error starting drive scan: {str(e)}")
        return jsonify({"error": f"Server error: {str(e)}"}), 500

@app.route('/scan/status', methods=['GET'])
def scan_status_endpoint():
    global scan_status
    if scan_status["status"] in ["completed", "error"]:
        return jsonify({
            "status": scan_status["status"],
            "stats": scan_status["stats"],
            "suspicious_files": scan_status["suspicious_files"][:50]
        })
    
    return jsonify({
        "status": scan_status["status"],
        "stats": scan_status["stats"]
    })

def is_file_suspicious(file_path):
    try:
        features = extract_static_features(file_path) or basic_file_analysis(file_path)
        risk_score, _, _ = calculate_risk_score(features, file_path)
        return risk_score > 0.4
    except Exception as e:
        logger.error(f"Error checking if file is suspicious: {str(e)}")
        return False

def calculate_risk_score(features, file_path):
    risk_score = 0.1
    suspicious_indicators = []
    
    if features.get("entropy", 0) > 7.0:
        risk_score += 0.3
        suspicious_indicators.append("High file entropy suggests possible packing or encryption")
    elif features.get("entropy", 0) > 6.0:
        risk_score += 0.1
    
    if "section_entropies" in features and features["section_entropies"]:
        high_entropy_sections = sum(1 for entropy in features["section_entropies"] if entropy > 7.0)
        if high_entropy_sections > 0:
            risk_score += 0.1 * min(high_entropy_sections, 3)
            suspicious_indicators.append(f"Found {high_entropy_sections} high-entropy sections")
    
    file_size = features.get("file_size", 0)
    is_executable = features.get("file_magic", "").lower().find("executable") >= 0
    
    if is_executable:
        if file_size < 100000:
            risk_score += 0.2
            suspicious_indicators.append("Unusually small executable size")
        elif file_size > 50 * 1024 * 1024:
            risk_score += 0.1
            suspicious_indicators.append("Unusually large executable size")
    
    strings = features.get("strings", [])
    suspicious_string_patterns = [
        r'http://', r'https://', r'cmd\.exe', r'powershell\.exe',
        r'CreateProcess', r'ShellExecute', r'registry', r'RegCreate',
        r'RegSet', r'kernel32', r'ntdll', r'URLDownload', r'InternetOpen'
    ]
    
    suspicious_string_count = 0
    for pattern in suspicious_string_patterns:
        for string in strings:
            if re.search(pattern, string, re.IGNORECASE):
                suspicious_string_count += 1
                break
    
    if suspicious_string_count > 0:
        risk_score += min(0.2, 0.05 * suspicious_string_count)
        suspicious_indicators.append(f"Found {suspicious_string_count} suspicious string patterns")
    
    if features.get("is_pe", False):
        if "has_overlay" in features and features["has_overlay"]:
            risk_score += 0.1
            suspicious_indicators.append("File contains overlay data")
        
        standard_section_names = {'.text', '.data', '.rdata', '.bss', '.rsrc', '.reloc', '.idata', '.edata', '.pdata'}
        if "sections" in features and features["sections"]:
            unusual_sections = [s for s in features["sections"] if s not in standard_section_names]
            if unusual_sections:
                risk_score += min(0.2, 0.05 * len(unusual_sections))
                suspicious_indicators.append(f"Unusual sections: {', '.join(unusual_sections[:3])}")
    
    # Enhanced checks for PE files
    if "imports" in features:
        suspicious_imports = {'CreateRemoteThread', 'VirtualAlloc', 'WriteProcessMemory',
                            'LoadLibrary', 'GetProcAddress'}
        found_suspicious = [imp for imp in features["imports"] if imp in suspicious_imports]
        if found_suspicious:
            risk_score += 0.2
            suspicious_indicators.append(f"Suspicious imports: {', '.join(found_suspicious[:3])}")
    
    if features.get("is_signed", False):
        risk_score = max(0.1, risk_score - 0.3)
        suspicious_indicators.append("File is digitally signed")
    
    risk_score = min(0.95, risk_score)
    risk_level = "High" if risk_score > 0.7 else "Medium" if risk_score > 0.4 else "Low"
    
    return risk_score, risk_level, suspicious_indicators

def extract_static_features(file_path):
    """Use static analysis module directly instead of duplicating functionality"""
    from static_analysis.analyze import extract_static_features as sa_extract_features
    return sa_extract_features(file_path)

def basic_file_analysis(file_path):
    try:
        file_size = os.path.getsize(file_path)
        file_ext = os.path.splitext(file_path)[1].lower()
        
        with open(file_path, 'rb') as f:
            data = f.read()
        
        md5_hash = hashlib.md5(data).hexdigest()
        sha256_hash = hashlib.sha256(data).hexdigest()
        entropy_value = shannon_entropy(data)
        
        strings_pattern = re.compile(b'[\x20-\x7f]{5,}')
        strings = strings_pattern.findall(data)
        
        # Only attempt PE analysis if file has an executable extension
        if file_ext.lower() in {'.exe', '.dll', '.sys', '.ocx', '.scr'}:
            is_pe = False
            if HAS_PEFILE:
                try:
                    pe = pefile.PE(file_path)
                    is_pe = True
                    imports = []
                    if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
                        for entry in pe.DIRECTORY_ENTRY_IMPORT:
                            for imp in entry.imports:
                                if imp.name:
                                    imports.append(imp.name.decode())
                    return {
                        "file_size": file_size,
                        "file_type": file_ext[1:] if file_ext else "unknown",
                        "md5": md5_hash,
                        "sha256": sha256_hash,
                        "entropy": entropy_value,
                        "strings": [s.decode(errors='ignore') for s in strings[:1000]],
                        "num_strings": len(strings),
                        "is_pe": True,
                        "imports": imports
                    }
                except Exception as e:
                    if "DOS Header" in str(e):
                        logger.info(f"Skipping non-PE file (invalid header): {file_path}")
                    else:
                        logger.warning(f"PE analysis error for {file_path}: {str(e)}")
        
        # Return basic analysis for non-PE or if PE analysis failed
        return {
            "file_size": file_size,
            "file_type": file_ext[1:] if file_ext else "unknown",
            "md5": md5_hash,
            "sha256": sha256_hash,
            "entropy": entropy_value,
            "strings": [s.decode(errors='ignore') for s in strings[:1000]],
            "num_strings": len(strings),
            "is_pe": False
        }
    except Exception as e:
        logger.error(f"Basic file analysis failed: {str(e)}")
        return {
            "file_size": os.path.getsize(file_path),
            "file_type": os.path.splitext(file_path)[1].lower()[1:],
            "error": str(e),
            "is_pe": False
        }

def calculate_file_hash(file_path):
    sha256 = hashlib.sha256()
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(4096), b''):
            sha256.update(chunk)
    return sha256.hexdigest()

def query_threat_intel(file_hash):
    results = {}
    VT_API_KEY = "YOUR_VIRUSTOTAL_API_KEY"  # Replace with your actual key
    
    try:
        vt_url = f"https://www.virustotal.com/api/v3/files/{file_hash}"
        headers = {"x-apikey": VT_API_KEY}
        response = requests.get(vt_url, headers=headers)
        if response.status_code == 200:
            results["virustotal"] = response.json()["data"]["attributes"]["last_analysis_stats"]
        elif response.status_code == 404:
            results["virustotal"] = {"status": "not_found"}
    except Exception as e:
        logger.error(f"VirusTotal query failed: {str(e)}")
        results["virustotal"] = {"error": str(e)}
    
    return results

if __name__ == '__main__':
    logger.info("Starting AI Malware Scanner API server on http://127.0.0.1:8001")
    logger.info("CORS is enabled for all origins")
    try:
        app.run(host='127.0.0.1', port=8001, debug=True)
    except Exception as e:
        logger.error(f"Failed to start server: {str(e)}")
        sys.exit(1)
    finally:
        for observer in observers:
            observer.stop()